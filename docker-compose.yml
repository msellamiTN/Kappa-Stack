version: '3.6'
volumes:
  shared-workspace:
    name: "Spark_Mongo1"
    driver: local
  rs11:
  rs12:
  rs13:

services:
  jupyterlab:
    image: jupyter/pyspark-notebook
    container_name: jupyterlab
    environment:
      - JUPYTER_ENABLE_LAB=yes
    ports:
      - 9988:8888
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - localnet
    restart: always

  spark-master:
    image: bde2020/spark-master
    container_name: spark-master
    ports:
      - 9080:8080
      - 8077:7077
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - localnet
    restart: always

  spark-worker-1:
    image: bde2020/spark-worker
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - 9081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - localnet
    restart: always

  spark-worker-2:
    image: bde2020/spark-worker
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - 9082:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - localnet
    restart: always

  mongo_api:
    image: mongo:latest
    command: --replSet rs0 --oplogSize 128 --bind_ip 0.0.0.0
    ports:
      - 28117:27017
    container_name: mongo1
    volumes:
      - rs11:/data/db
    networks:
      - localnet
    restart: always

  mongo2:
    image: "mongo:latest"
    container_name: mongo2
    command: --replSet rs0 --oplogSize 128 --bind_ip 0.0.0.0
    volumes:
      - rs12:/data/db
    networks:
      - localnet
    ports:
      - "28118:27017"
    restart: always

  mongo3:
    image: "mongo:latest"
    container_name: mongo3
    command: --replSet rs0 --oplogSize 128 --bind_ip 0.0.0.0
    volumes:
      - rs13:/data/db
    networks:
      - localnet
    ports:
      - "28119:27017"
    restart: always

  zookeeper:
    image: confluentinc/cp-zookeeper:6.0.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "32181:32181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:6.0.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:32181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://146.59.240.83:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  portainer:
    image: portainer/portainer
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./portainer-data:/data
        # Enable you to access potainers web interface from your host machine
        # using http://localhost:10001
    ports:
      - "10001:9000"
  
  cassandra:
    image: docker.io/bitnami/cassandra:3-debian-10
    ports:
      - 7000:7000
      - 9042:9042
    volumes:
      - cassandra_data:/bitnami
    environment:
      - CASSANDRA_SEEDS=cassandra,cassandra2
      - CASSANDRA_CLUSTER_NAME=cassandra-cluster
      - CASSANDRA_PASSWORD_SEEDER=yes
      - CASSANDRA_PASSWORD=cassandra
      # By default, Cassandra autodetects the available host memory and takes as much as it can.
      # Therefore, memory options are mandatory if multiple Cassandras are launched in the same node.
      - MAX_HEAP_SIZE=2G
      - HEAP_NEWSIZE=200M
  cassandra2:
    image: docker.io/bitnami/cassandra:3-debian-10
    ports:
      - 7001:7000
      - 9043:9042
    volumes:
      - cassandra2_data:/bitnami
    environment:
      - CASSANDRA_SEEDS=cassandra,cassandra2
      - CASSANDRA_CLUSTER_NAME=cassandra-cluster
      - CASSANDRA_PASSWORD=cassandra
      # By default, Cassandra autodetects the available host memory and takes as much as it can.
      # Therefore, memory options are mandatory if multiple Cassandras are launched in the same node.
      - MAX_HEAP_SIZE=2G
      - HEAP_NEWSIZE=200M
      # A web based interface for managing your docker containers.
       
networks:
    localnet:
        attachable: true
